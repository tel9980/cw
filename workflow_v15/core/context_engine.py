# -*- coding: utf-8 -*-
"""
Context Engine
ä¸Šä¸‹æ–‡å¼•æ“ - åˆ†æç”¨æˆ·è¡Œä¸ºã€ä¸šåŠ¡æ¨¡å¼å’Œå½“å‰çŠ¶æ€ä»¥æä¾›æ™ºèƒ½è¾…åŠ©
"""

import logging
import json
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
from collections import defaultdict, Counter

from ..models.context_models import (
    ContextAnalysis,
    UserPatterns,
    TimeContext,
    SmartDefault,
    Alternative,
    Task,
    Activity,
    Priority,
    Dashboard,
    TaskPriority,
    BusinessCyclePosition
)

logger = logging.getLogger(__name__)


class ContextEngine:
    """
    ä¸Šä¸‹æ–‡å¼•æ“
    
    è´Ÿè´£ï¼š
    - åˆ†æç”¨æˆ·è¡Œä¸ºæ¨¡å¼
    - é¢„æµ‹ä¸‹ä¸€æ­¥æ“ä½œ
    - ç”Ÿæˆæ™ºèƒ½é»˜è®¤å€¼
    - ä»ç”¨æˆ·çº æ­£ä¸­å­¦ä¹ 
    - ç”Ÿæˆä¸ªæ€§åŒ–ä»ªè¡¨æ¿
    
    Requirements: 4.1, 4.2, 4.3, 4.5, 8.1, 8.2
    """
    
    def __init__(self, storage_path: str = "è´¢åŠ¡æ•°æ®/context_data"):
        """
        åˆå§‹åŒ–ä¸Šä¸‹æ–‡å¼•æ“
        
        Args:
            storage_path: ä¸Šä¸‹æ–‡æ•°æ®å­˜å‚¨è·¯å¾„
        """
        self.storage_path = Path(storage_path)
        self.storage_path.mkdir(parents=True, exist_ok=True)
        
        self.user_patterns_cache: Dict[str, UserPatterns] = {}
        self.activity_history: Dict[str, List[Activity]] = defaultdict(list)
        
        # å†å²äº¤æ˜“æ•°æ®ç”¨äºæ™ºèƒ½é»˜è®¤å€¼ç”Ÿæˆ
        self.transaction_history: Dict[str, List[Dict[str, Any]]] = defaultdict(list)
        
        # çº æ­£å­¦ä¹ æ•°æ®
        self.correction_history: Dict[str, List[Dict[str, Any]]] = defaultdict(list)
        
        # å®¢æˆ·/ä¾›åº”å•†æ¨¡å¼
        self.entity_patterns: Dict[str, Dict[str, Any]] = defaultdict(dict)
        
        # åŠ è½½æŒä¹…åŒ–æ•°æ®
        self._load_persistent_data()
        
        logger.info("ContextEngine initialized with storage at %s", self.storage_path)

    def analyze_current_context(
        self, 
        user_id: str,
        current_time: Optional[datetime] = None
    ) -> ContextAnalysis:
        """
        åˆ†æå½“å‰ä¸Šä¸‹æ–‡
        
        Args:
            user_id: ç”¨æˆ·ID
            current_time: å½“å‰æ—¶é—´ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¸ºç°åœ¨ï¼‰
            
        Returns:
            ContextAnalysis: ä¸Šä¸‹æ–‡åˆ†æç»“æœ
        """
        if current_time is None:
            current_time = datetime.now()
        
        # è·å–æˆ–åˆ›å»ºç”¨æˆ·æ¨¡å¼
        user_patterns = self._get_user_patterns(user_id)
        
        # åˆ†ææ—¶é—´ä¸Šä¸‹æ–‡
        time_context = TimeContext.from_datetime(current_time)
        
        # è·å–å¾…å¤„ç†ä»»åŠ¡
        pending_tasks = self._get_pending_tasks(user_id, time_context)
        
        # è·å–æœ€è¿‘æ´»åŠ¨
        recent_activities = self._get_recent_activities(user_id, hours=24)
        
        # ç”Ÿæˆä¼˜å…ˆçº§å»ºè®®
        suggested_priorities = self._generate_priorities(
            user_patterns, 
            time_context, 
            pending_tasks
        )
        
        # è®¡ç®—ç½®ä¿¡åº¦
        confidence = self._calculate_confidence(user_patterns, recent_activities)
        
        analysis = ContextAnalysis(
            user_id=user_id,
            analysis_time=current_time,
            user_patterns=user_patterns,
            current_time_context=time_context,
            pending_tasks=pending_tasks,
            recent_activities=recent_activities,
            business_cycle_position=time_context.business_cycle,
            suggested_priorities=suggested_priorities,
            confidence_score=confidence
        )
        
        logger.info(f"Analyzed context for user {user_id}, confidence: {confidence:.2f}")
        return analysis

    def _get_user_patterns(self, user_id: str) -> UserPatterns:
        """è·å–ç”¨æˆ·è¡Œä¸ºæ¨¡å¼"""
        if user_id in self.user_patterns_cache:
            return self.user_patterns_cache[user_id]
        
        # åˆ›å»ºæ–°çš„ç”¨æˆ·æ¨¡å¼
        patterns = UserPatterns(user_id=user_id)
        self.user_patterns_cache[user_id] = patterns
        return patterns
    
    def _get_pending_tasks(
        self, 
        user_id: str, 
        time_context: TimeContext
    ) -> List[Task]:
        """è·å–å¾…å¤„ç†ä»»åŠ¡"""
        tasks = []
        
        # æ ¹æ®æ—¶é—´ä¸Šä¸‹æ–‡ç”Ÿæˆä»»åŠ¡
        if time_context.business_cycle == BusinessCyclePosition.MONTH_END:
            tasks.append(Task(
                task_id="month_end_close",
                name="æœˆæœ«ç»“è´¦",
                description="æ‰§è¡Œæœˆæœ«ç»“è´¦æµç¨‹",
                priority=TaskPriority.HIGH,
                estimated_duration=120
            ))
        
        return tasks
    
    def _get_recent_activities(
        self, 
        user_id: str, 
        hours: int = 24
    ) -> List[Activity]:
        """è·å–æœ€è¿‘çš„æ´»åŠ¨è®°å½•"""
        cutoff_time = datetime.now() - timedelta(hours=hours)
        activities = self.activity_history.get(user_id, [])
        return [a for a in activities if a.timestamp >= cutoff_time]

    def _generate_priorities(
        self,
        user_patterns: UserPatterns,
        time_context: TimeContext,
        pending_tasks: List[Task]
    ) -> List[Priority]:
        """ç”Ÿæˆä¼˜å…ˆçº§å»ºè®®"""
        priorities = []
        
        # åŸºäºæ—¶é—´ä¸Šä¸‹æ–‡çš„ä¼˜å…ˆçº§
        if time_context.time_type.value == "morning":
            priorities.append(Priority(
                item_id="morning_review",
                title="æŸ¥çœ‹ä»Šæ—¥ä»»åŠ¡",
                description="æ£€æŸ¥ä»Šå¤©éœ€è¦å®Œæˆçš„å·¥ä½œ",
                priority=TaskPriority.HIGH,
                reason="æ—©æ™¨å¼€å§‹å·¥ä½œ",
                suggested_action="æŸ¥çœ‹æ—¥å¿—å’Œå¾…åŠäº‹é¡¹"
            ))
        
        # åŸºäºå¾…å¤„ç†ä»»åŠ¡çš„ä¼˜å…ˆçº§
        for task in pending_tasks:
            if task.priority in [TaskPriority.URGENT, TaskPriority.HIGH]:
                priorities.append(Priority(
                    item_id=task.task_id,
                    title=task.name,
                    description=task.description,
                    priority=task.priority,
                    reason="é‡è¦å¾…åŠä»»åŠ¡",
                    suggested_action=task.name
                ))
        
        return priorities
    
    def _calculate_confidence(
        self,
        user_patterns: UserPatterns,
        recent_activities: List[Activity]
    ) -> float:
        """è®¡ç®—åˆ†æç½®ä¿¡åº¦"""
        # åŸºäºæ•°æ®é‡è®¡ç®—ç½®ä¿¡åº¦
        activity_count = len(recent_activities)
        pattern_count = len(user_patterns.function_usage_count)
        
        confidence = min(1.0, (activity_count * 0.01 + pattern_count * 0.05))
        return max(0.1, confidence)  # æœ€å°ç½®ä¿¡åº¦0.1

    def predict_next_action(
        self, 
        current_state: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """
        é¢„æµ‹ä¸‹ä¸€æ­¥æ“ä½œ
        
        åŸºäºä»¥ä¸‹å› ç´ é¢„æµ‹ï¼š
        - ç”¨æˆ·å¸¸ç”¨åŠŸèƒ½
        - æ—¶é—´ä¸Šä¸‹æ–‡
        - å·¥ä½œæµåºåˆ—æ¨¡å¼
        - æœ€è¿‘æ´»åŠ¨
        
        Args:
            current_state: å½“å‰çŠ¶æ€ä¿¡æ¯
            
        Returns:
            List[Dict]: é¢„æµ‹çš„æ“ä½œåˆ—è¡¨ï¼ŒæŒ‰ç½®ä¿¡åº¦æ’åº
        
        Requirements: 8.1
        """
        user_id = current_state.get('user_id', 'default_user')
        patterns = self._get_user_patterns(user_id)
        current_time = current_state.get('current_time', datetime.now())
        
        predictions = []
        
        # 1. åŸºäºå¸¸ç”¨åŠŸèƒ½é¢„æµ‹
        top_functions = patterns.get_top_functions(10)
        for i, func_code in enumerate(top_functions):
            base_confidence = 0.7 - (i * 0.05)  # é€’å‡ç½®ä¿¡åº¦
            
            # è°ƒæ•´åŸºäºæ—¶é—´åå¥½çš„ç½®ä¿¡åº¦
            if func_code in patterns.preferred_time_slots:
                time_slots = patterns.preferred_time_slots[func_code]
                current_hour = current_time.hour
                
                # å¦‚æœå½“å‰æ—¶é—´æ˜¯è¯¥åŠŸèƒ½çš„å¸¸ç”¨æ—¶é—´ï¼Œæé«˜ç½®ä¿¡åº¦
                hour_counter = Counter(time_slots)
                if current_hour in hour_counter:
                    time_boost = min(0.2, hour_counter[current_hour] / len(time_slots))
                    base_confidence += time_boost
            
            predictions.append({
                'function_code': func_code,
                'confidence': min(0.95, base_confidence),
                'reason': 'å¸¸ç”¨åŠŸèƒ½',
                'metadata': {
                    'usage_count': patterns.function_usage_count.get(func_code, 0)
                }
            })
        
        # 2. åŸºäºå·¥ä½œæµåºåˆ—é¢„æµ‹
        recent_activities = self._get_recent_activities(user_id, hours=1)
        if recent_activities:
            recent_sequence = [a.function_code for a in recent_activities[-5:]]
            
            # æŸ¥æ‰¾åŒ¹é…çš„å·¥ä½œæµåºåˆ—
            for workflow_seq in patterns.typical_workflow_sequences:
                # æ£€æŸ¥æœ€è¿‘çš„æ´»åŠ¨æ˜¯å¦åŒ¹é…å·¥ä½œæµåºåˆ—çš„å¼€å§‹éƒ¨åˆ†
                if len(recent_sequence) < len(workflow_seq):
                    match_length = 0
                    for i, func in enumerate(recent_sequence):
                        if i < len(workflow_seq) and workflow_seq[i] == func:
                            match_length += 1
                        else:
                            break
                    
                    # å¦‚æœæœ‰åŒ¹é…ï¼Œé¢„æµ‹åºåˆ—ä¸­çš„ä¸‹ä¸€ä¸ªåŠŸèƒ½
                    if match_length > 0 and match_length < len(workflow_seq):
                        next_func = workflow_seq[match_length]
                        confidence = 0.8 * (match_length / len(workflow_seq))
                        
                        # æ£€æŸ¥æ˜¯å¦å·²ç»åœ¨é¢„æµ‹åˆ—è¡¨ä¸­
                        existing = next((p for p in predictions if p['function_code'] == next_func), None)
                        if existing:
                            # æé«˜ç°æœ‰é¢„æµ‹çš„ç½®ä¿¡åº¦
                            existing['confidence'] = min(0.95, existing['confidence'] + confidence * 0.3)
                            existing['reason'] = 'å¸¸ç”¨åŠŸèƒ½ + å·¥ä½œæµåºåˆ—'
                        else:
                            predictions.append({
                                'function_code': next_func,
                                'confidence': confidence,
                                'reason': 'å·¥ä½œæµåºåˆ—æ¨¡å¼',
                                'metadata': {
                                    'sequence_match': recent_sequence,
                                    'expected_sequence': workflow_seq
                                }
                            })
        
        # 3. åŸºäºæ—¶é—´ä¸Šä¸‹æ–‡é¢„æµ‹
        time_context = TimeContext.from_datetime(current_time)
        
        if time_context.time_type.value == "morning":
            # æ—©æ™¨å¯èƒ½éœ€è¦æŸ¥çœ‹æŠ¥è¡¨æˆ–å¤„ç†å¾…åŠäº‹é¡¹
            predictions.append({
                'function_code': 'view_dashboard',
                'confidence': 0.75,
                'reason': 'æ—©æ™¨å¼€å§‹å·¥ä½œ',
                'metadata': {'time_context': 'morning'}
            })
        
        if time_context.business_cycle == BusinessCyclePosition.MONTH_END:
            # æœˆæœ«å¯èƒ½éœ€è¦ç»“è´¦ç›¸å…³åŠŸèƒ½
            predictions.append({
                'function_code': 'month_end_close',
                'confidence': 0.85,
                'reason': 'æœˆæœ«ç»“è´¦',
                'metadata': {'business_cycle': 'month_end'}
            })
        
        # æŒ‰ç½®ä¿¡åº¦æ’åº
        predictions.sort(key=lambda x: x['confidence'], reverse=True)
        
        # å»é‡ï¼ˆä¿ç•™ç½®ä¿¡åº¦æœ€é«˜çš„ï¼‰
        seen_functions = set()
        unique_predictions = []
        for pred in predictions:
            if pred['function_code'] not in seen_functions:
                seen_functions.add(pred['function_code'])
                unique_predictions.append(pred)
        
        logger.info(f"Generated {len(unique_predictions)} predictions for user {user_id}")
        return unique_predictions[:10]  # è¿”å›å‰10ä¸ªé¢„æµ‹
    
    def generate_smart_defaults(
        self, 
        transaction_type: str, 
        context: Dict[str, Any]
    ) -> Dict[str, SmartDefault]:
        """
        ç”Ÿæˆæ™ºèƒ½é»˜è®¤å€¼
        
        åŸºäºä»¥ä¸‹å› ç´ ç”Ÿæˆæ™ºèƒ½é»˜è®¤å€¼ï¼š
        - å†å²äº¤æ˜“æ¨¡å¼
        - å®¢æˆ·/ä¾›åº”å•†å…³ç³»
        - ä¸šåŠ¡å‘¨æœŸ
        - ç”¨æˆ·ä¹ æƒ¯
        
        Args:
            transaction_type: äº¤æ˜“ç±»å‹
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆåŒ…å«user_id, entity_idç­‰ï¼‰
            
        Returns:
            Dict[str, SmartDefault]: å­—æ®µååˆ°æ™ºèƒ½é»˜è®¤å€¼çš„æ˜ å°„
        
        Requirements: 4.1, 4.2, 4.5
        """
        defaults = {}
        user_id = context.get('user_id', 'default_user')
        
        # æ—¥æœŸé»˜è®¤å€¼ - åŸºäºä¸šåŠ¡è§„åˆ™
        current_time = datetime.now()
        defaults['date'] = SmartDefault(
            field_name='date',
            suggested_value=current_time.strftime('%Y-%m-%d'),
            confidence=1.0,
            reasoning='å½“å‰æ—¥æœŸ',
            source='business_rules'
        )
        
        # å¦‚æœæä¾›äº†å®ä½“IDï¼ˆå®¢æˆ·/ä¾›åº”å•†ï¼‰ï¼Œä½¿ç”¨å®ä½“æ¨¡å¼
        entity_id = context.get('entity_id')
        if entity_id and entity_id in self.entity_patterns:
            entity_pattern = self.entity_patterns[entity_id]
            
            # ç±»åˆ«é»˜è®¤å€¼ - åŸºäºè¯¥å®ä½“çš„å†å²äº¤æ˜“
            if entity_pattern['typical_categories']:
                most_common_category = entity_pattern['typical_categories'].most_common(1)[0]
                category_value, category_count = most_common_category
                total_count = entity_pattern['transaction_count']
                confidence = category_count / total_count if total_count > 0 else 0.5
                
                # ç”Ÿæˆå¤‡é€‰é¡¹
                alternatives = []
                for cat, count in entity_pattern['typical_categories'].most_common(3)[1:]:
                    alt_confidence = count / total_count if total_count > 0 else 0.3
                    alternatives.append(Alternative(
                        value=cat,
                        confidence=alt_confidence,
                        reasoning=f'è¯¥å®ä½“çš„æ¬¡å¸¸ç”¨ç±»åˆ«ï¼ˆ{count}æ¬¡ï¼‰'
                    ))
                
                defaults['category'] = SmartDefault(
                    field_name='category',
                    suggested_value=category_value,
                    confidence=confidence,
                    reasoning=f'è¯¥å®ä½“æœ€å¸¸ç”¨çš„ç±»åˆ«ï¼ˆ{category_count}/{total_count}æ¬¡ï¼‰',
                    alternatives=alternatives,
                    source='entity_pattern'
                )
            
            # é‡‘é¢é»˜è®¤å€¼ - åŸºäºå†å²å¹³å‡å€¼
            if entity_pattern['typical_amounts']:
                amounts = entity_pattern['typical_amounts']
                avg_amount = sum(amounts) / len(amounts)
                # ä½¿ç”¨æœ€è¿‘çš„é‡‘é¢ä½œä¸ºæ›´é«˜ç½®ä¿¡åº¦çš„å»ºè®®
                recent_amount = amounts[-1] if amounts else avg_amount
                
                defaults['amount'] = SmartDefault(
                    field_name='amount',
                    suggested_value=recent_amount,
                    confidence=0.8,
                    reasoning=f'è¯¥å®ä½“æœ€è¿‘ä¸€æ¬¡äº¤æ˜“é‡‘é¢',
                    alternatives=[
                        Alternative(
                            value=avg_amount,
                            confidence=0.6,
                            reasoning=f'è¯¥å®ä½“å¹³å‡äº¤æ˜“é‡‘é¢ï¼ˆåŸºäº{len(amounts)}ç¬”äº¤æ˜“ï¼‰'
                        )
                    ],
                    source='entity_pattern'
                )
            
            # ä»˜æ¬¾æ¡æ¬¾é»˜è®¤å€¼
            if entity_pattern['typical_payment_terms']:
                most_common_terms = entity_pattern['typical_payment_terms'].most_common(1)[0]
                terms_value, terms_count = most_common_terms
                total_count = entity_pattern['transaction_count']
                confidence = terms_count / total_count if total_count > 0 else 0.5
                
                defaults['payment_terms'] = SmartDefault(
                    field_name='payment_terms',
                    suggested_value=terms_value,
                    confidence=confidence,
                    reasoning=f'è¯¥å®ä½“å¸¸ç”¨çš„ä»˜æ¬¾æ¡æ¬¾ï¼ˆ{terms_count}/{total_count}æ¬¡ï¼‰',
                    source='entity_pattern'
                )
        
        # åŸºäºäº¤æ˜“ç±»å‹å’Œç”¨æˆ·å†å²æä¾›é»˜è®¤å€¼
        user_transactions = self.transaction_history.get(user_id, [])
        type_transactions = [t for t in user_transactions if t['type'] == transaction_type]
        
        if type_transactions and 'category' not in defaults:
            # åˆ†æè¯¥ç±»å‹äº¤æ˜“çš„ç±»åˆ«åˆ†å¸ƒ
            category_counter = Counter()
            for trans in type_transactions:
                if 'category' in trans['data']:
                    category_counter[trans['data']['category']] += 1
            
            if category_counter:
                most_common = category_counter.most_common(1)[0]
                category_value, count = most_common
                confidence = count / len(type_transactions)
                
                alternatives = []
                for cat, cat_count in category_counter.most_common(3)[1:]:
                    alternatives.append(Alternative(
                        value=cat,
                        confidence=cat_count / len(type_transactions),
                        reasoning=f'æ‚¨å¸¸ç”¨çš„ç±»åˆ«ï¼ˆ{cat_count}æ¬¡ï¼‰'
                    ))
                
                defaults['category'] = SmartDefault(
                    field_name='category',
                    suggested_value=category_value,
                    confidence=confidence,
                    reasoning=f'æ‚¨æœ€å¸¸ç”¨çš„{transaction_type}ç±»åˆ«ï¼ˆ{count}/{len(type_transactions)}æ¬¡ï¼‰',
                    alternatives=alternatives,
                    source='user_pattern'
                )
        
        # åŸºäºä¸šåŠ¡å‘¨æœŸæä¾›é»˜è®¤å€¼
        time_context = TimeContext.from_datetime(current_time)
        if time_context.business_cycle == BusinessCyclePosition.MONTH_END:
            # æœˆæœ«å¯èƒ½éœ€è¦ç‰¹æ®Šå¤„ç†
            if 'notes' not in defaults:
                defaults['notes'] = SmartDefault(
                    field_name='notes',
                    suggested_value='æœˆæœ«ç»“è´¦',
                    confidence=0.6,
                    reasoning='å½“å‰å¤„äºæœˆæœ«ï¼Œå¯èƒ½æ˜¯ç»“è´¦ç›¸å…³äº¤æ˜“',
                    source='business_cycle'
                )
        
        # ä»çº æ­£å†å²ä¸­å­¦ä¹ 
        corrections = self.correction_history.get(user_id, [])
        relevant_corrections = [
            c for c in corrections
            if c.get('transaction_type') == transaction_type
        ]
        
        if relevant_corrections:
            # åˆ†æç”¨æˆ·ç»å¸¸çº æ­£çš„å­—æ®µ
            for correction in relevant_corrections[-10:]:  # æœ€è¿‘10æ¬¡çº æ­£
                field = correction.get('field')
                actual_value = correction.get('actual_value')
                
                if field and actual_value and field not in defaults:
                    defaults[field] = SmartDefault(
                        field_name=field,
                        suggested_value=actual_value,
                        confidence=0.7,
                        reasoning='åŸºäºæ‚¨ä¹‹å‰çš„çº æ­£å­¦ä¹ ',
                        source='correction_learning'
                    )
        
        logger.info(f"Generated {len(defaults)} smart defaults for {transaction_type}")
        return defaults

    def learn_from_correction(
        self, 
        prediction: Dict[str, Any], 
        actual: Dict[str, Any]
    ) -> None:
        """
        ä»ç”¨æˆ·çº æ­£ä¸­å­¦ä¹ 
        
        åˆ†æé¢„æµ‹å€¼å’Œå®é™…å€¼çš„å·®å¼‚ï¼Œæ›´æ–°æ¨¡å¼ä»¥æ”¹è¿›æœªæ¥é¢„æµ‹ã€‚
        
        Args:
            prediction: ç³»ç»Ÿé¢„æµ‹çš„å€¼
            actual: ç”¨æˆ·å®é™…è¾“å…¥çš„å€¼
        
        Requirements: 4.3, 8.2
        """
        user_id = actual.get('user_id', 'default_user')
        patterns = self._get_user_patterns(user_id)
        
        # æ›´æ–°åŠŸèƒ½ä½¿ç”¨è®¡æ•°
        if 'function_code' in actual:
            func_code = actual['function_code']
            patterns.function_usage_count[func_code] = \
                patterns.function_usage_count.get(func_code, 0) + 1
        
        # è®°å½•çº æ­£è¯¦æƒ…
        correction_record = {
            'timestamp': datetime.now().isoformat(),
            'transaction_type': actual.get('transaction_type'),
            'entity_id': actual.get('entity_id'),
            'corrections': []
        }
        
        # åˆ†ææ¯ä¸ªå­—æ®µçš„çº æ­£
        for field, predicted_value in prediction.items():
            if field in actual and actual[field] != predicted_value:
                correction_record['corrections'].append({
                    'field': field,
                    'predicted_value': predicted_value,
                    'actual_value': actual[field],
                    'prediction_confidence': prediction.get(f'{field}_confidence', 0.5)
                })
                
                # å¦‚æœæ˜¯å®ä½“ç›¸å…³çš„çº æ­£ï¼Œæ›´æ–°å®ä½“æ¨¡å¼
                entity_id = actual.get('entity_id')
                if entity_id and entity_id in self.entity_patterns:
                    entity_pattern = self.entity_patterns[entity_id]
                    
                    if field == 'category':
                        # å¢åŠ å®é™…ç±»åˆ«çš„æƒé‡
                        entity_pattern['typical_categories'][actual[field]] += 2
                        # å‡å°‘é¢„æµ‹ç±»åˆ«çš„æƒé‡ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                        if predicted_value in entity_pattern['typical_categories']:
                            entity_pattern['typical_categories'][predicted_value] = max(
                                0, entity_pattern['typical_categories'][predicted_value] - 1
                            )
                    
                    elif field == 'payment_terms':
                        # å¢åŠ å®é™…ä»˜æ¬¾æ¡æ¬¾çš„æƒé‡
                        entity_pattern['typical_payment_terms'][actual[field]] += 2
                        if predicted_value in entity_pattern['typical_payment_terms']:
                            entity_pattern['typical_payment_terms'][predicted_value] = max(
                                0, entity_pattern['typical_payment_terms'][predicted_value] - 1
                            )
        
        # åªè®°å½•æœ‰çº æ­£çš„æƒ…å†µ
        if correction_record['corrections']:
            self.correction_history[user_id].append(correction_record)
            
            # ä¿æŒå†å²è®°å½•åœ¨åˆç†å¤§å°ï¼ˆæœ€å¤š1000æ¡ï¼‰
            if len(self.correction_history[user_id]) > 1000:
                self.correction_history[user_id] = self.correction_history[user_id][-1000:]
            
            logger.info(
                f"Learned from {len(correction_record['corrections'])} corrections for user {user_id}"
            )
            
            # æŒä¹…åŒ–
            self._save_correction_history(user_id)
            if actual.get('entity_id'):
                self._save_entity_patterns()
        
        # è®°å½•çº æ­£ä¿¡æ¯ç”¨äºæœªæ¥æ”¹è¿›
        patterns.last_updated = datetime.now()
        self._save_user_patterns(user_id, patterns)
    
    def get_personalized_dashboard(
        self, 
        user_id: str, 
        time_context: Optional[str] = None
    ) -> Dashboard:
        """
        ç”Ÿæˆä¸ªæ€§åŒ–ä»ªè¡¨æ¿
        
        Args:
            user_id: ç”¨æˆ·ID
            time_context: æ—¶é—´ä¸Šä¸‹æ–‡ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            Dashboard: ä¸ªæ€§åŒ–ä»ªè¡¨æ¿
        """
        # åˆ†æå½“å‰ä¸Šä¸‹æ–‡
        context = self.analyze_current_context(user_id)
        
        # è·å–é«˜ä¼˜å…ˆçº§ä»»åŠ¡
        priority_tasks = context.get_high_priority_tasks()
        
        # ç”Ÿæˆå¿«é€Ÿæ“ä½œ
        quick_actions = []
        for func_code in context.user_patterns.get_top_functions(5):
            quick_actions.append({
                'function_code': func_code,
                'name': f'åŠŸèƒ½ {func_code}',
                'is_frequent': True
            })
        
        # ç”Ÿæˆå¾…å¤„ç†é¡¹
        pending_items = [
            {
                'type': 'task',
                'title': task.name,
                'priority': task.priority.value
            }
            for task in context.pending_tasks
        ]
        
        # ç”Ÿæˆæ´å¯Ÿ
        insights = self._generate_insights(context)
        
        dashboard = Dashboard(
            user_id=user_id,
            generated_at=datetime.now(),
            context=context,
            priority_tasks=priority_tasks,
            quick_actions=quick_actions,
            pending_items=pending_items,
            insights=insights
        )
        
        logger.info(f"Generated personalized dashboard for user {user_id}")
        return dashboard
    
    def _generate_insights(self, context: ContextAnalysis) -> List[str]:
        """ç”Ÿæˆæ´å¯Ÿä¿¡æ¯"""
        insights = []
        
        if context.current_time_context.business_cycle == BusinessCyclePosition.MONTH_END:
            insights.append("ğŸ“… æœ¬æœˆå³å°†ç»“æŸï¼Œå»ºè®®å¼€å§‹å‡†å¤‡æœˆæœ«ç»“è´¦å·¥ä½œ")
        
        if len(context.pending_tasks) > 5:
            insights.append(f"âš ï¸ æ‚¨æœ‰ {len(context.pending_tasks)} ä¸ªå¾…å¤„ç†ä»»åŠ¡")
        
        return insights
    
    def analyze_workflow_patterns(
        self,
        user_id: str,
        min_sequence_length: int = 3,
        min_occurrences: int = 2
    ) -> List[List[str]]:
        """
        åˆ†æç”¨æˆ·çš„å·¥ä½œæµåºåˆ—æ¨¡å¼
        
        è¯†åˆ«ç”¨æˆ·ç»å¸¸æ‰§è¡Œçš„åŠŸèƒ½åºåˆ—ï¼Œç”¨äºé¢„æµ‹å’Œå»ºè®®ã€‚
        
        Args:
            user_id: ç”¨æˆ·ID
            min_sequence_length: æœ€å°åºåˆ—é•¿åº¦
            min_occurrences: æœ€å°å‡ºç°æ¬¡æ•°
            
        Returns:
            List[List[str]]: è¯†åˆ«å‡ºçš„å·¥ä½œæµåºåˆ—æ¨¡å¼
        
        Requirements: 8.1
        """
        activities = self.activity_history.get(user_id, [])
        if len(activities) < min_sequence_length:
            return []
        
        # æå–åŠŸèƒ½ä»£ç åºåˆ—
        function_sequence = [a.function_code for a in activities]
        
        # æŸ¥æ‰¾é‡å¤çš„å­åºåˆ—
        patterns = []
        sequence_counter = Counter()
        
        # æ»‘åŠ¨çª—å£æŸ¥æ‰¾æ¨¡å¼
        for length in range(min_sequence_length, min(10, len(function_sequence))):
            for i in range(len(function_sequence) - length + 1):
                subsequence = tuple(function_sequence[i:i+length])
                sequence_counter[subsequence] += 1
        
        # ç­›é€‰å‡ºç°æ¬¡æ•°è¶³å¤Ÿçš„æ¨¡å¼
        for sequence, count in sequence_counter.items():
            if count >= min_occurrences:
                patterns.append(list(sequence))
        
        # æŒ‰åºåˆ—é•¿åº¦å’Œå‡ºç°æ¬¡æ•°æ’åº
        patterns.sort(key=lambda x: (len(x), sequence_counter[tuple(x)]), reverse=True)
        
        # æ›´æ–°ç”¨æˆ·æ¨¡å¼
        user_patterns = self._get_user_patterns(user_id)
        user_patterns.typical_workflow_sequences = patterns[:20]  # ä¿ç•™å‰20ä¸ªæ¨¡å¼
        self._save_user_patterns(user_id, user_patterns)
        
        logger.info(f"Identified {len(patterns)} workflow patterns for user {user_id}")
        return patterns
    
    def get_correction_insights(
        self,
        user_id: str,
        field: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        è·å–çº æ­£å­¦ä¹ çš„æ´å¯Ÿ
        
        åˆ†æç”¨æˆ·çš„çº æ­£å†å²ï¼Œè¯†åˆ«ç³»ç»Ÿé¢„æµ‹çš„å¼±ç‚¹ã€‚
        
        Args:
            user_id: ç”¨æˆ·ID
            field: å¯é€‰ï¼Œç‰¹å®šå­—æ®µçš„æ´å¯Ÿ
            
        Returns:
            Dict: çº æ­£æ´å¯Ÿä¿¡æ¯
        
        Requirements: 4.3, 8.2
        """
        corrections = self.correction_history.get(user_id, [])
        if not corrections:
            return {
                'total_corrections': 0,
                'field_accuracy': {},
                'improvement_areas': []
            }
        
        # ç»Ÿè®¡å„å­—æ®µçš„çº æ­£æƒ…å†µ
        field_corrections = Counter()
        field_total = Counter()
        
        for correction_record in corrections:
            for correction in correction_record.get('corrections', []):
                corrected_field = correction['field']
                field_corrections[corrected_field] += 1
                field_total[corrected_field] += 1
        
        # è®¡ç®—å‡†ç¡®ç‡ï¼ˆå‡è®¾æ€»é¢„æµ‹æ¬¡æ•°æ˜¯çº æ­£æ¬¡æ•°çš„10å€ï¼‰
        field_accuracy = {}
        for f in field_total:
            estimated_total = field_total[f] * 10
            accuracy = 1.0 - (field_corrections[f] / estimated_total)
            field_accuracy[f] = max(0.0, accuracy)
        
        # è¯†åˆ«éœ€è¦æ”¹è¿›çš„é¢†åŸŸ
        improvement_areas = []
        for f, accuracy in field_accuracy.items():
            if accuracy < 0.7:
                improvement_areas.append({
                    'field': f,
                    'accuracy': accuracy,
                    'correction_count': field_corrections[f]
                })
        
        improvement_areas.sort(key=lambda x: x['accuracy'])
        
        insights = {
            'total_corrections': sum(field_corrections.values()),
            'field_accuracy': field_accuracy,
            'improvement_areas': improvement_areas,
            'most_corrected_fields': field_corrections.most_common(5)
        }
        
        if field and field in field_accuracy:
            insights['field_specific'] = {
                'field': field,
                'accuracy': field_accuracy[field],
                'correction_count': field_corrections[field]
            }
        
        return insights
    
    def get_entity_insights(
        self,
        entity_id: str
    ) -> Optional[Dict[str, Any]]:
        """
        è·å–å®ä½“ï¼ˆå®¢æˆ·/ä¾›åº”å•†ï¼‰çš„æ´å¯Ÿ
        
        Args:
            entity_id: å®ä½“ID
            
        Returns:
            Dict: å®ä½“æ´å¯Ÿä¿¡æ¯ï¼Œå¦‚æœå®ä½“ä¸å­˜åœ¨åˆ™è¿”å›None
        
        Requirements: 4.2
        """
        if entity_id not in self.entity_patterns:
            return None
        
        pattern = self.entity_patterns[entity_id]
        
        insights = {
            'entity_id': entity_id,
            'transaction_count': pattern['transaction_count'],
            'typical_categories': dict(pattern['typical_categories'].most_common(5)),
            'typical_payment_terms': dict(pattern['typical_payment_terms'].most_common(3)),
            'last_transaction': pattern['last_transaction']
        }
        
        # è®¡ç®—å¹³å‡é‡‘é¢å’Œæ ‡å‡†å·®
        if pattern['typical_amounts']:
            amounts = pattern['typical_amounts']
            avg_amount = sum(amounts) / len(amounts)
            variance = sum((x - avg_amount) ** 2 for x in amounts) / len(amounts)
            std_dev = variance ** 0.5
            
            insights['amount_statistics'] = {
                'average': avg_amount,
                'std_deviation': std_dev,
                'min': min(amounts),
                'max': max(amounts),
                'recent': amounts[-1] if amounts else None
            }
        
        return insights
    
    def record_activity(
        self, 
        user_id: str, 
        activity: Activity
    ) -> None:
        """
        è®°å½•ç”¨æˆ·æ´»åŠ¨
        
        Args:
            user_id: ç”¨æˆ·ID
            activity: æ´»åŠ¨è®°å½•
        """
        self.activity_history[user_id].append(activity)
        
        # æ›´æ–°ç”¨æˆ·æ¨¡å¼
        patterns = self._get_user_patterns(user_id)
        patterns.function_usage_count[activity.function_code] = \
            patterns.function_usage_count.get(activity.function_code, 0) + 1
        patterns.last_updated = datetime.now()
        
        # æ›´æ–°æ—¶é—´åå¥½
        hour = activity.timestamp.hour
        if activity.function_code not in patterns.preferred_time_slots:
            patterns.preferred_time_slots[activity.function_code] = []
        patterns.preferred_time_slots[activity.function_code].append(hour)
        
        # æŒä¹…åŒ–
        self._save_user_patterns(user_id, patterns)
    
    def record_transaction(
        self,
        user_id: str,
        transaction_type: str,
        transaction_data: Dict[str, Any]
    ) -> None:
        """
        è®°å½•äº¤æ˜“æ•°æ®ç”¨äºæ¨¡å¼å­¦ä¹ 
        
        Args:
            user_id: ç”¨æˆ·ID
            transaction_type: äº¤æ˜“ç±»å‹
            transaction_data: äº¤æ˜“æ•°æ®
        
        Requirements: 4.1, 4.2
        """
        transaction_record = {
            'type': transaction_type,
            'data': transaction_data,
            'timestamp': datetime.now().isoformat()
        }
        self.transaction_history[user_id].append(transaction_record)
        
        # æ›´æ–°å®ä½“æ¨¡å¼ï¼ˆå®¢æˆ·/ä¾›åº”å•†ï¼‰
        if 'entity_id' in transaction_data:
            entity_id = transaction_data['entity_id']
            if entity_id not in self.entity_patterns:
                self.entity_patterns[entity_id] = {
                    'transaction_count': 0,
                    'typical_amounts': [],
                    'typical_categories': Counter(),
                    'typical_payment_terms': Counter(),
                    'last_transaction': None
                }
            
            entity_pattern = self.entity_patterns[entity_id]
            entity_pattern['transaction_count'] += 1
            
            if 'amount' in transaction_data:
                entity_pattern['typical_amounts'].append(transaction_data['amount'])
            
            if 'category' in transaction_data:
                entity_pattern['typical_categories'][transaction_data['category']] += 1
            
            if 'payment_terms' in transaction_data:
                entity_pattern['typical_payment_terms'][transaction_data['payment_terms']] += 1
            
            entity_pattern['last_transaction'] = transaction_data
        
        # æŒä¹…åŒ–
        self._save_transaction_history(user_id)
        self._save_entity_patterns()
    
    def _load_persistent_data(self) -> None:
        """åŠ è½½æŒä¹…åŒ–æ•°æ®"""
        # åŠ è½½ç”¨æˆ·æ¨¡å¼
        patterns_file = self.storage_path / "user_patterns.json"
        if patterns_file.exists():
            try:
                with open(patterns_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    for user_id, pattern_data in data.items():
                        patterns = UserPatterns(
                            user_id=user_id,
                            function_usage_count=pattern_data.get('function_usage_count', {}),
                            preferred_time_slots=pattern_data.get('preferred_time_slots', {}),
                            typical_workflow_sequences=pattern_data.get('typical_workflow_sequences', []),
                            average_session_duration=pattern_data.get('average_session_duration', 0.0)
                        )
                        self.user_patterns_cache[user_id] = patterns
            except Exception as e:
                logger.error(f"Failed to load user patterns: {e}")
        
        # åŠ è½½äº¤æ˜“å†å²
        transaction_file = self.storage_path / "transaction_history.json"
        if transaction_file.exists():
            try:
                with open(transaction_file, 'r', encoding='utf-8') as f:
                    self.transaction_history = defaultdict(list, json.load(f))
            except Exception as e:
                logger.error(f"Failed to load transaction history: {e}")
        
        # åŠ è½½å®ä½“æ¨¡å¼
        entity_file = self.storage_path / "entity_patterns.json"
        if entity_file.exists():
            try:
                with open(entity_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    for entity_id, pattern_data in data.items():
                        # è½¬æ¢Counterå¯¹è±¡
                        pattern_data['typical_categories'] = Counter(
                            pattern_data.get('typical_categories', {})
                        )
                        pattern_data['typical_payment_terms'] = Counter(
                            pattern_data.get('typical_payment_terms', {})
                        )
                        self.entity_patterns[entity_id] = pattern_data
            except Exception as e:
                logger.error(f"Failed to load entity patterns: {e}")
        
        # åŠ è½½çº æ­£å†å²
        correction_file = self.storage_path / "correction_history.json"
        if correction_file.exists():
            try:
                with open(correction_file, 'r', encoding='utf-8') as f:
                    self.correction_history = defaultdict(list, json.load(f))
            except Exception as e:
                logger.error(f"Failed to load correction history: {e}")
    
    def _save_user_patterns(self, user_id: str, patterns: UserPatterns) -> None:
        """ä¿å­˜ç”¨æˆ·æ¨¡å¼"""
        patterns_file = self.storage_path / "user_patterns.json"
        
        # åŠ è½½ç°æœ‰æ•°æ®
        all_patterns = {}
        if patterns_file.exists():
            try:
                with open(patterns_file, 'r', encoding='utf-8') as f:
                    all_patterns = json.load(f)
            except Exception as e:
                logger.error(f"Failed to load existing patterns: {e}")
        
        # æ›´æ–°æ•°æ®
        all_patterns[user_id] = {
            'function_usage_count': patterns.function_usage_count,
            'preferred_time_slots': patterns.preferred_time_slots,
            'typical_workflow_sequences': patterns.typical_workflow_sequences,
            'average_session_duration': patterns.average_session_duration
        }
        
        # ä¿å­˜
        try:
            with open(patterns_file, 'w', encoding='utf-8') as f:
                json.dump(all_patterns, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"Failed to save user patterns: {e}")
    
    def _save_transaction_history(self, user_id: str) -> None:
        """ä¿å­˜äº¤æ˜“å†å²"""
        transaction_file = self.storage_path / "transaction_history.json"
        
        try:
            with open(transaction_file, 'w', encoding='utf-8') as f:
                json.dump(dict(self.transaction_history), f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"Failed to save transaction history: {e}")
    
    def _save_entity_patterns(self) -> None:
        """ä¿å­˜å®ä½“æ¨¡å¼"""
        entity_file = self.storage_path / "entity_patterns.json"
        
        # è½¬æ¢Counterå¯¹è±¡ä¸ºdict
        serializable_patterns = {}
        for entity_id, pattern in self.entity_patterns.items():
            serializable_patterns[entity_id] = {
                'transaction_count': pattern['transaction_count'],
                'typical_amounts': pattern['typical_amounts'],
                'typical_categories': dict(pattern['typical_categories']),
                'typical_payment_terms': dict(pattern['typical_payment_terms']),
                'last_transaction': pattern['last_transaction']
            }
        
        try:
            with open(entity_file, 'w', encoding='utf-8') as f:
                json.dump(serializable_patterns, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"Failed to save entity patterns: {e}")
    
    def _save_correction_history(self, user_id: str) -> None:
        """ä¿å­˜çº æ­£å†å²"""
        correction_file = self.storage_path / "correction_history.json"
        
        try:
            with open(correction_file, 'w', encoding='utf-8') as f:
                json.dump(dict(self.correction_history), f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"Failed to save correction history: {e}")
